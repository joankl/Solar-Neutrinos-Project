{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b5f0f8c-64cc-4a9d-bb76-2d60e68dc935",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Construcción de Técnicas de Normalización para Datos en Histograma time residual  vs cos(α)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "627568c7-5e39-4ea8-9e4b-b91b2e04e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b305cda-ea1e-4b82-a4b5-16b8fa335f9f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def magnitude(vector): \n",
    "    #Funcion para calcular radio de eventos al centro del detector\n",
    "    \n",
    "    norm = []\n",
    "    for vec in vector:\n",
    "    \tnorm.append(np.linalg.norm(vec))\n",
    "\n",
    "    return np.array(norm, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a54fc2e-9a29-48c1-b570-6e94b007913c",
   "metadata": {},
   "source": [
    "# 1 - Extraer datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e55ba8-ce29-433b-9ec6-0af1cb700945",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T;34', 'T;33', 'pmt;2', 'pmt;1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = uproot.open(\"/snoplus simulations/electron bulk/random point/random dir/High Statistic/simu_Analysis_elec_2.5MeV.root\")\n",
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b50121aa-0ef3-42ea-a160-3d1b34a08354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['evtid',\n",
       " 'mcID',\n",
       " 'energy',\n",
       " 'mc_position',\n",
       " 'mc_momentum',\n",
       " 'position',\n",
       " 'momentum',\n",
       " 'hit_pmtid',\n",
       " 'hit_pmttime',\n",
       " 'hit_residual',\n",
       " 'hit_type']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = file['T;34']\n",
    "data1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66783e95-44ea-47fc-9e46-f3c62f37753c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pmt_id', 'pmt_pos_xyz', 'pmt_pos_sph', 'pmt_type']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmt_info = file['pmt;1']\n",
    "pmt_info.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511d10e9-c43b-4ea4-bdb5-288854dfb102",
   "metadata": {},
   "source": [
    "## 1.1 - EV info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1716c6-2557-4c14-95ff-509c5ebd0719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evtid = np.array(data1['evtid'], dtype = np.int16)\n",
    "mcID = np.array(data1['mcID'], dtype = np.int16)\n",
    "mc_position = np.array(data1['mc_position'])  # -> Position Generation\n",
    "mc_momentum = np.array(data1['mc_momentum'])  # -> IMPORTANT: Direction of simulated event\n",
    "position = np.array(data1['position'])        \n",
    "hit_pmtid = np.array(data1['hit_pmtid'], dtype = np.int16)\n",
    "time_residual = np.array(data1['hit_residual'])\n",
    "hit_type = np.array(data1['hit_type'], dtype = np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "952075cb-b982-4b9c-a221-3fec7d018fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.61017013, -0.21758524,  1.39451194])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_momentum[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ad399-1f02-4d69-b1b5-7b9f0afe0cdc",
   "metadata": {},
   "source": [
    "## 1.2 - PMT info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c237ba8-7610-4df9-9561-884bec49ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmt_id = np.array(pmt_info['pmt_id'], dtype = np.int16)\n",
    "pmt_pos_xyz = np.array(pmt_info['pmt_pos_xyz'])\n",
    "pmt_pos_sph = np.array(pmt_info['pmt_pos_sph'])\n",
    "pmt_type = np.array(pmt_info['pmt_type'], dtype = np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "137cd9c4-e4a7-4e82-8bd7-9f9ec42911c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.99990e+04, -9.99990e+04, -9.99990e+04],\n",
       "       [ 5.46754e+03,  6.34400e+01, -6.40627e+03],\n",
       "       [ 5.61516e+03,  2.66800e+02, -6.25109e+03],\n",
       "       ...,\n",
       "       [ 4.97000e+02, -5.57700e+03,  7.30100e+03],\n",
       "       [ 3.96400e+03, -4.70800e+03,  6.84000e+03],\n",
       "       [ 2.03200e+03, -2.09800e+03,  8.72900e+03]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmt_pos_xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a28535d-fc23-4293-95a9-83d6a2e26296",
   "metadata": {},
   "source": [
    "# 2 - Extract Valid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3caf140-9945-4bdc-be91-321e9f38b953",
   "metadata": {},
   "source": [
    "## 2.1 - Extract  valid PMT id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53adeea1-eb88-44f7-a12f-346328a85469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,        1,        2, ..., 71917473, 71917474, 71917475],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_pmt_id = np.array(np.where(pmt_type == 1)[0])   # PMT valid ID match with index of where pmt_type=1\n",
    "\n",
    "valid_id_info_ev_i = np.array(np.where(np.in1d(hit_pmtid, valid_pmt_id))[0])\n",
    "valid_id_info_ev_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f2ad4c-27e3-40e5-9dcb-44b1fd32e6d8",
   "metadata": {},
   "source": [
    "### 2.1.1 - Extraer información valida de PMT info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5da8599-181e-4e59-b1d8-145eba204b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pmt_xyz = []\n",
    "\n",
    "for i_dx in valid_pmt_id:\n",
    "    valid_pmt_xyz.append(pmt_pos_xyz[i_dx])\n",
    "valid_pmt_xyz = np.array(valid_pmt_xyz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740e7992-15a3-45d7-90a9-98ac728c4caf",
   "metadata": {},
   "source": [
    "### 2.1.2 - Encontrar el nº de PMTs disponibles dentro de cada intervalo de cos(α) en todo el Detector\n",
    "\n",
    "1. Transformar datos por una translación (sumar a cada coordenada de PMT el vector vertex de MC y reconstruido)\n",
    "2. Calcular cos(α) para todos los PMTs\n",
    "3. Dividir α en subsecciones (corresponder al binning del histograma). Usaremos el cos(α). α variar entre [0,π], y cos(α) entre [-1,1]\n",
    "4. Contabilizar el nº de PMTs dentro de está sección y guardar esta información -> Nº de PMTs = Nº de datos en cos(Δα)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ff74188b-ba40-4bcb-bc3f-d63070830fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.98445576, -0.98553305, -0.98579542, ..., -0.62689144,\n",
       "       -0.58241994, -0.61186463])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute cos(angle)\n",
    "vec_ev = mc_momentum[0]\n",
    "cos_angle = []\n",
    "\n",
    "#Deslocation of PSUP by a vector equal to the mc_vertex\n",
    "#for example:\n",
    "T_vector = mc_position[0]\n",
    "T_pmt_xyz = valid_pmt_xyz + T_vector\n",
    "\n",
    "N = np.shape(valid_pmt_xyz)[0] \n",
    "for i in range(N):\n",
    "    scalar_product = np.dot(T_pmt_xyz[i],vec_ev)\n",
    "    norm_1 = np.linalg.norm(T_pmt_xyz[i])\n",
    "    norm_2 = np.linalg.norm(vec_ev)\n",
    "    cos_val = scalar_product/(norm_1*norm_2)\n",
    "    cos_angle.append(cos_val)\n",
    "cos_angle = np.array(cos_angle)\n",
    "cos_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c2eca4-9920-401f-a9fc-7c8581ec1fc4",
   "metadata": {},
   "source": [
    "### 2.1.3 - Gráfico de Distribuición de PMTs\n",
    "\n",
    "Este gráfico muestra como los se observa la Distribución de PMTs cuando salimos del centro del Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d6cb0eed-0836-4d7e-aaa1-659cefc9da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "# Now devide the cos_angel in sections, lets use an Histogram and then extract the counts per bin\n",
    "bins = 40\n",
    "\n",
    "title = 'Nº of PMT in cos(Δα) section'\n",
    "ytitle = 'PMT counts'\n",
    "xtitle = 'cos(α)'\n",
    "\n",
    "aval_PMT, x_, y_ = plt.hist(cos_angle, bins = bins, edgecolor='black', facecolor='g')\n",
    "plt.ylabel(ytitle)\n",
    "plt.xlabel(xtitle)\n",
    "plt.title(title)\n",
    "plt.show()\n",
    "\n",
    "aval_PMT = aval_PMT.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78947819-f66b-4866-a6f0-d2a1b1739aea",
   "metadata": {},
   "source": [
    "## 2.2 - Extracción y cortes en Datos de Eventos Validos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e65999de-bf66-4ecf-86ae-acceadef5f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slipt nº: 0\n",
      "In radi_cut, split nº:  0\n",
      "computing cos(alpha)\n",
      "doing time residual cuts\n",
      "slipt nº: 1\n",
      "In radi_cut, split nº:  1\n",
      "computing cos(alpha)\n",
      "doing time residual cuts\n",
      "slipt nº: 2\n",
      "In radi_cut, split nº:  2\n",
      "computing cos(alpha)\n",
      "doing time residual cuts\n",
      "slipt nº: 3\n",
      "In radi_cut, split nº:  3\n",
      "computing cos(alpha)\n",
      "doing time residual cuts\n",
      "slipt nº: 4\n",
      "In radi_cut, split nº:  4\n",
      "computing cos(alpha)\n",
      "doing time residual cuts\n",
      "slipt nº: 5\n",
      "In radi_cut, split nº:  5\n",
      "computing cos(alpha)\n",
      "doing time residual cuts\n",
      "slipt nº: 6\n",
      "In radi_cut, split nº:  6\n",
      "computing cos(alpha)\n",
      "doing time residual cuts\n",
      "slipt nº: 7\n",
      "In radi_cut, split nº:  7\n",
      "computing cos(alpha)\n",
      "doing time residual cuts\n"
     ]
    }
   ],
   "source": [
    "#params to adjust the cuts--------------------------------------------\n",
    "#Split Data\n",
    "split = 8\n",
    "#time cut\n",
    "inf_cut = -5\n",
    "up_cut = 15\n",
    "\n",
    "#radia cut\n",
    "radi_cut_method = True   #If true, apply radial cuts given by rad_cut_val to data\n",
    "rad_cut_val = 5500.0\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Dividir valid_id_info_ev_i en partes\n",
    "valid_info_ev_split = np.array_split(valid_id_info_ev_i, split)  #---> split(array, parts)\n",
    "\n",
    "#variables to save: with time residual cuts and radi cut (radi cut is optional, depends on the simulation)\n",
    "multi_time_residual_cut = []\n",
    "multi_cos_angle_cut = []\n",
    "multi_position_cut = []\n",
    "multi_mc_momentum_cut = []\n",
    "multi_mc_ID_cut = []\n",
    "\n",
    "#loop over valid_info_ev_split\n",
    "for n_loop, split_array in enumerate(valid_info_ev_split):\n",
    "    print('slipt nº:', n_loop)\n",
    "    # extract all valid simulated info \n",
    "    multi_mc_ID = []\n",
    "    multi_time_residual = []\n",
    "    multi_pmt_id_hit = []\n",
    "    multi_position = []\n",
    "    #multi_mc_position = []\n",
    "    multi_mc_momentum = []   \n",
    "    multi_xyz_hit = []\n",
    "\n",
    "    for valid_i in split_array:\n",
    "        multi_mc_ID.append(mcID[valid_i])\n",
    "        multi_time_residual.append(time_residual[valid_i])\n",
    "        multi_pmt_id_hit.append(hit_pmtid[valid_i])\n",
    "        multi_position.append(position[valid_i])\n",
    "        #multi_mc_position.append(mc_position[valid_i])\n",
    "        multi_mc_momentum.append(mc_momentum[valid_i])\n",
    "    multi_time_residual = np.array(multi_time_residual)\n",
    "    multi_pmt_id_hit = np.array(multi_pmt_id_hit)\n",
    "    multi_position = np.array(multi_position)\n",
    "\n",
    "    for id_i in multi_pmt_id_hit:\n",
    "        multi_xyz_hit.append(pmt_pos_xyz[id_i])\n",
    "    multi_xyz_hit = np.array(multi_xyz_hit)\n",
    "\n",
    "    #Radial Cut:\n",
    "    if radi_cut_method == True:\n",
    "        print('In radi_cut, split nº: ', n_loop)\n",
    "        #mc_position_norm = magnitude(multi_mc_position)\n",
    "        position_norm = magnitude(multi_position)\n",
    "        max_radi = rad_cut_val\n",
    "        radi_condition = (position_norm < max_radi)\n",
    "        index_cut_radi = np.array(np.where(radi_condition)[0])\n",
    "\n",
    "        #variables to extract\n",
    "        multi_time_residual = np.extract(radi_condition, multi_time_residual)\n",
    "        multi_pmt_id_hit = np.extract(radi_condition, multi_pmt_id_hit)\n",
    "\n",
    "        multi_mc_ID_radi_cut = []\n",
    "        multi_mc_momentum_radi_cut = []\n",
    "        multi_position_radi_cut = []\n",
    "        multi_xyz_hit_radi_cut = [] \n",
    "\n",
    "        for j_dx in index_cut_radi:\n",
    "            multi_mc_momentum_radi_cut.append(multi_mc_momentum[j_dx])\n",
    "            multi_position_radi_cut.append(multi_position[j_dx])          #HERE\n",
    "            multi_mc_ID_radi_cut.append(multi_mc_ID[j_dx])\n",
    "\n",
    "        for id_i in multi_pmt_id_hit:\n",
    "            multi_xyz_hit_radi_cut.append(pmt_pos_xyz[id_i])\n",
    "\n",
    "        multi_mc_ID = multi_mc_ID_radi_cut\n",
    "        multi_mc_momentum = multi_mc_momentum_radi_cut   #HERE\n",
    "        multi_position = multi_position_radi_cut\n",
    "        multi_xyz_hit = multi_xyz_hit_radi_cut\n",
    "        \n",
    "        #freed memory\n",
    "        multi_mc_ID_radi_cut = None\n",
    "        multi_mc_momentum_radi_cut = None\n",
    "        multi_position_radi_cut = None\n",
    "        multi_xyz_hit_radi_cut = None\n",
    "        radi_condition = None\n",
    "        index_cut_radi = None\n",
    "        \n",
    "    #cos(alpha) calculation -> Uses the definition of scalar product\n",
    "    multi_cos_angle = []\n",
    "    N = np.shape(multi_xyz_hit)[0]\n",
    "\n",
    "    print('computing cos(alpha)')\n",
    "    for k in range(N):\n",
    "        \n",
    "        scalar_product = np.dot(multi_xyz_hit[k], multi_mc_momentum[k])\n",
    "        norm_1 = np.linalg.norm(multi_mc_momentum[k])\n",
    "        norm_2 = np.linalg.norm(multi_xyz_hit[k])\n",
    "        cos_val = scalar_product/(norm_1*norm_2)\n",
    "        \n",
    "        multi_cos_angle.append(cos_val)\n",
    "\n",
    "    #Time residual cut:\n",
    "    print('doing time residual cuts')\n",
    "    for i in np.where((multi_time_residual > inf_cut) & (multi_time_residual < up_cut))[0]:\n",
    "        multi_time_residual_cut.append(multi_time_residual[i])\n",
    "        multi_cos_angle_cut.append(multi_cos_angle[i])\n",
    "        multi_position_cut.append(multi_position[i])\n",
    "        multi_mc_momentum_cut.append(multi_mc_momentum[i])\n",
    "        multi_mc_ID_cut.append(multi_mc_ID[i])\n",
    "\n",
    "    #freed memory\n",
    "    multi_cos_angle = None\n",
    "\n",
    "    #freen memory:    \n",
    "    multi_mc_ID = None\n",
    "    multi_time_residual = None\n",
    "    multi_pmt_id_hit = None\n",
    "    multi_position = None\n",
    "    multi_mc_position = None\n",
    "    multi_mc_momentum = None\n",
    "    multi_xyz_hit = None\n",
    "    \n",
    "multi_position_cut = np.array(multi_position_cut)\n",
    "multi_mc_momentum_cut = np.array(multi_mc_momentum_cut)\n",
    "multi_mc_ID_cut = np.array(multi_mc_ID_cut, dtype = np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e30961-ab01-4a9c-8104-62faa2c050c2",
   "metadata": {},
   "source": [
    "# 3 - Histograma 2D: time residual vs. cos(α)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "576780a7-2491-4fb5-8145-40db1eab6998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib\n",
    "# 2d Histogram\n",
    "bins = 35\n",
    "#Titles\n",
    "\n",
    "if radi_cut_method == True:\n",
    "    title = 'cos(α) vs. Time Residual Multiple evID - 2.5MeV - random (dir, vtx) \\n volume cut r(mm) < '+str(rad_cut_val)\n",
    "    file_name = 'cos(α) vs time residual multiple evID 2.5MeV_' + str(rad_cut_val) + '_mm' + str(bins)\n",
    "\n",
    "else:\n",
    "    title = 'cos(α) vs. time residual - Multiple evID - 2.5MeV - random (dir,vtx)'\n",
    "    file_name = 'cos(α) vs time Residual multiple evID 2.5MeV_'+ str(bins)\n",
    "    \n",
    "ylabel = 'cos(α)'\n",
    "xlabel = 'time residual'\n",
    "\n",
    "#bins defined above when computing the Nº of PMTs in each Δα!\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sn.set_style(rc = {'axes.facecolor': 'black'})\n",
    "sn.histplot(x = multi_cos_angle_cut, y = multi_time_residual_cut, bins = [bins, bins], stat='count', cbar = 'True', cmap = cm.nipy_spectral, hue_norm = (0,1))\n",
    "plt.ylabel(ylabel)\n",
    "plt.xlabel(xlabel)\n",
    "plt.title(title, fontsize= 10)\n",
    "\n",
    "#equal acis ration\n",
    "#ax = plt.gca()\n",
    "#ax.set_aspect('equal', adjustable='box')\n",
    "plt.savefig('figs/High Stat/'+file_name+'.png', format = 'png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5e7581-6d3d-4e32-af0d-7789762d8e3d",
   "metadata": {},
   "source": [
    "# 3 - Construcción Histograma Normalizados \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ea00c3-ae70-4717-a4f9-6eb0ccdb2bb9",
   "metadata": {},
   "source": [
    "## 3.1 - Extraer Información a Normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce83cbb9-1dee-48f7-a68f-65bcfe6d8408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x2847fcbdf40>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforma Data into an Image Matrix\n",
    "H, xedges, yedges = np.histogram2d(x = multi_cos_angle_cut, y = multi_time_residual_cut, bins = [bins, bins])\n",
    "\n",
    "#Now recover the data axis representation of time residual vs cos(alpha)\n",
    "left = np.min(multi_time_residual_cut)\n",
    "right = np.max(multi_time_residual_cut)\n",
    "bottom = np.min(multi_cos_angle_cut)\n",
    "top = np.max(multi_cos_angle_cut)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(H, extent = [left, right, top, bottom], aspect=\"auto\" ) #---> Here is our image as a Matrix Pixel\n",
    "plt.title(title, fontsize= 10)\n",
    "plt.ylabel(ylabel)\n",
    "plt.xlabel(xlabel)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeda202-9b07-46e4-95db-d40905c982dc",
   "metadata": {},
   "source": [
    "### 3.2 - Metodo 1: Dividir por el Nº de PMTs que dan hit en cada bin de cos(α)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7b800c9-f17f-4d3f-830a-4ba5b5f3fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of hits in each bin = sum over each column element of the matrix.\n",
    "sum_hit = np.sum(H,axis=0)  \n",
    "\n",
    "H_normalized1 = H / sum_hit\n",
    "\n",
    "if radi_cut_method == True:\n",
    "    N1title = 'Normalization by NHits - Multiple evID - 2.5MeV - random (dir, vtx) \\n volume cut r(mm) < '+str(rad_cut_val)\n",
    "    file_name = 'Normalization by NHits multiple evID 2.5MeV_' + str(rad_cut_val) + '_mm' + str(bins)\n",
    "\n",
    "else:\n",
    "    N1title = 'Normalization by NHits - Multiple evID - 2.5MeV - random (dir, vtx)'\n",
    "    file_name = 'Normalization by NHits multiple evID 2.5MeV_' + str(bins)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(H_normalized1, extent = [left, right, top, bottom], aspect=\"auto\", vmin = 0.0, vmax = 0.07)\n",
    "plt.title(N1title, fontsize= 10)\n",
    "plt.ylabel(ylabel)\n",
    "plt.xlabel(xlabel)\n",
    "plt.colorbar()\n",
    "plt.savefig('figs/High Stat/'+file_name+'.png', format = 'png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6556d782-68f9-4e4b-8fed-ee4c1c10cf32",
   "metadata": {},
   "source": [
    "### 3.3 - Metodo 2: Dividir por el Nº de PMTs disponibles en cada bin de cos(α)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "58e28efa-a75a-4884-ae22-7737d0852f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1e3dac33f50>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_normalized2 = H / aval_PMT\n",
    "\n",
    "if radi_cut_method == True:\n",
    "    \n",
    "    N2title = 'Normalization by Nº PMTs in cos(α) section - Multiple evID - 2.5MeV - random (dir, vtx) \\n volume cut r(mm) < '+str(rad_cut_val)\n",
    "\n",
    "else:\n",
    "    N2title = 'Normalization by Nº PMTs in cos(α) section - Multiple evID - 2.5MeV - random (dir, vtx)'\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(H_normalized2, extent = [left, right, top, bottom], aspect=\"auto\" )\n",
    "plt.title(N2title)\n",
    "plt.ylabel(ylabel)\n",
    "plt.xlabel(xlabel)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb90889-9781-4698-aac5-26e7ea909468",
   "metadata": {},
   "source": [
    "## 3.4 - Metodo Random Vertex\n",
    "\n",
    "En este metodo cada evento debera ser normalizado por el denominador $N_{Hits}(cosα)/N_{PMT}(cosα)$. Será necesario extraer la distribución de PMTs en el detector dado el vertice del evento y extraer los hits dentro de cada cos(Δα) para asi obterner la normalizacion deseada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cd3647-7853-47c8-9561-b8bfc099cabd",
   "metadata": {},
   "source": [
    "### 3.4.1 - Extraer Datos\n",
    "\n",
    "Es necesario extraer datos de evento a eventos de modo a contabilizar la distribucion de PMTs dados. 1) vertex fuera de centro; 2) direccion del evento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc24e674-0d84-479a-a423-86ea08e89820",
   "metadata": {},
   "source": [
    "#### - Encontrar indices donde mcID cambia de número"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc2d76d7-092e-4613-99d7-7735e6dfab86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "break_i = [0] #List of indices where data change of event ID\n",
    "\n",
    "N_evts = len(multi_mc_ID_cut)\n",
    "for i in range(N_evts-1):\n",
    "    if multi_mc_ID_cut[i] != multi_mc_ID_cut[i+1]:\n",
    "        break_i.append(i+1)    \n",
    "break_i = np.array(break_i, dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4bce1a9-c1cc-4463-8d39-326f54c1aad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,      308,      731, ..., 27718295, 27718748, 27719051])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "break_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6395a90e-6053-41d4-9747-7dbeaf61b881",
   "metadata": {},
   "source": [
    "#### - Extraer los datos que corren entre los elementos de break_i y construir normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7282bba-087f-4f25-a748-1d9ef401397f",
   "metadata": {},
   "source": [
    "Estrategia de corte de calidad:\n",
    "\n",
    "- cortar eventos con pocos puntos: Tomemos N_ev, si len(time_residual) < 1000 Datos -> Pass\n",
    "- obligar outliers de pico alto a ser cero: implementación -> comparar con los maximos de histogramas regulares, y si algun histograma tiene un punto que exceda un limite regular de counts, entonces convertir este elemento de matriz en cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a0c9203-fd9f-4cb6-bbdf-242850722a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joanc\\AppData\\Local\\Temp\\ipykernel_17456\\2822777069.py:43: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_data = H_ev/norm_factor\n"
     ]
    }
   ],
   "source": [
    "N_breaks = len(break_i)\n",
    "bins = 35\n",
    "H3_i = [] # Will save all the images, event by event. To get the superpostion of images we just have to sum all images in H3\n",
    "H3_all = np.zeros((bins,bins))  #All superpostions\n",
    "norm_factor_ctrl = []\n",
    "for i_dx in range(1, N_breaks):\n",
    "\n",
    "    #Data to be used in each mcID value\n",
    "    init_i = break_i[i_dx-1]\n",
    "    final_i = break_i[i_dx]\n",
    "    \n",
    "    time_residual_ev = multi_time_residual_cut[init_i:final_i]\n",
    "    cos_angle_ev = multi_cos_angle_cut[init_i:final_i]\n",
    "    mc_momentum_ev = multi_mc_momentum_cut[init_i]\n",
    "    position_ev = multi_position_cut[init_i]\n",
    "\n",
    "    #Nº of events control: There are events with an incoherent number of events - cut them.\n",
    "    N_ev = len(time_residual_ev)\n",
    "    #if N_ev < 1000:\n",
    "        #continue\n",
    "\n",
    "    #Use each Data to construct Histograms:\n",
    "    #1) event Histogram and counts\n",
    "    H_ev, _, _ = np.histogram2d(x = cos_angle_ev, y = time_residual_ev, bins = [bins, bins])\n",
    "    sum_hit = np.sum(H_ev, axis=0) \n",
    "\n",
    "    #2) Use the postion and mc_momentum to obtain the PMT distribution\n",
    "    pmt_cos_angle = []    # angle of PMTs relative to the mc_momentum_ev\n",
    "    T_pmt_xyz = valid_pmt_xyz + position_ev   #Translation transformation of PMT info data\n",
    "    N = np.shape(valid_pmt_xyz)[0]\n",
    "    for i in range(N):\n",
    "        scalar_product = np.dot(T_pmt_xyz[i], mc_momentum_ev)\n",
    "        norm_1 = np.linalg.norm(T_pmt_xyz[i])\n",
    "        norm_2 = np.linalg.norm(mc_momentum_ev)\n",
    "        cos_val = scalar_product/(norm_1*norm_2)\n",
    "        pmt_cos_angle.append(cos_val)\n",
    "    pmt_cos_angle = np.array(pmt_cos_angle, dtype = np.float32)\n",
    "    N_pmt, _ = np.histogram(pmt_cos_angle, bins = bins)\n",
    "\n",
    "    norm_factor = (sum_hit / N_pmt)\n",
    "    norm_factor_ctrl.append(norm_factor)\n",
    "\n",
    "    norm_data = H_ev/norm_factor\n",
    "    norm_data = np.nan_to_num(norm_data, nan = 0.0)\n",
    "\n",
    "    H3_i.append(norm_data)\n",
    "    H3_all += norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9599278-ffff-4765-9461-5fccf359903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avoid under/oveflow bins:\n",
    "\n",
    "row_f = np.shape(H3_all)[0]    #selection of cut on rows\n",
    "column_f = np.shape(H3_all)[1] #selection of cut on cloumns\n",
    "\n",
    "H3_del1 = np.delete(H3_all,[0,row_f-1], 0) #del extremal row\n",
    "H3_del2 = np.delete(H3_all,[0,column_f-1], 1) #del extremal column\n",
    "H3_all_del = H3_del2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a7ffa2-6aaa-45d5-ab46-17a1a31435a0",
   "metadata": {},
   "source": [
    "#### - See Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fa06927-c28a-48fb-9951-0a04f0fc1adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x2847ff32600>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One event image\n",
    "\n",
    "plt.imshow(H3_i[9], extent = [left, right, top, bottom], aspect=\"auto\")#, vmin = 0, vmax = 350) \n",
    "plt.ylabel(ylabel)\n",
    "plt.xlabel(xlabel) \n",
    "plt.colorbar()\n",
    "#plt.savefig('figs/Low Stat/uni_event4_NormNhit_div_Npmt.png', format = 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "087df5d6-845a-4890-a233-3815822fd115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x287dcebf410>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All event image\n",
    "\n",
    "plt.imshow(H3_all, extent = [left, right, top, bottom], aspect=\"auto\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b4d4d70-bbe3-4dec-b82a-7017e170a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = len(multi_time_residual_cut)\n",
    "\n",
    "left_del = np.min(multi_time_residual_cut[1:data_size-2])\n",
    "right_del = np.max(multi_time_residual_cut[1:data_size-2])\n",
    "bottom_del = np.min(multi_cos_angle_cut[1:data_size-2])\n",
    "top_del = np.max(multi_cos_angle_cut[1:data_size-2])\n",
    "\n",
    "if radi_cut_method == True: \n",
    "    title = 'Norm by Nhits/Npmt - Multiple evID - 2.5MeV - r(mm) < '+str(rad_cut_val)\n",
    "    filename = 'norm NHits_Npmt_2.5MeV_' + str(rad_cut_val) + 'mm_' + str(bins)\n",
    "\n",
    "else:\n",
    "    title = 'Norm by Nhits/Npmt - Multiple evID - 2.5MeV'\n",
    "    filename = 'norm NHits_Npmt_2.5MeV_' + str(bins)\n",
    "\n",
    "\n",
    "plt.imshow(H3_all_del, extent = [left_del, right_del, top_del, bottom_del], aspect=\"auto\") #All event image\n",
    "plt.ylabel(ylabel)\n",
    "plt.xlabel(xlabel)\n",
    "plt.title(title, fontsize = 10)\n",
    "plt.colorbar()\n",
    "plt.savefig('figs/High Stat/'+filename+'.png', format = 'png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb2f7f1-38b7-4872-8ae1-54c35cbafdba",
   "metadata": {},
   "source": [
    "# 4 - Analisis de Sistematicos\n",
    "\n",
    "Comparación entre mc_position y recons_position (más información en notebook Volume Cut Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e386d0d1-fd65-4487-bdef-c1bc5ec0c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load normalized data using mc_position, and recons_postion\n",
    "H_normalized_mc = np.genfromtxt('norm_observable_info-mc_position-5500.0_60.csv', delimiter=',')\n",
    "H_normalized_recons = np.genfromtxt('norm_observable_info-recons_position-5500.0_60.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db56e12f-372c-45ac-a6a8-5093563a7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_ratio = (H_normalized_mc+1)/(H_normalized_recons+1)  #sumamos +1 para evitar divisiones por 0\n",
    "ratio = np.ravel(H_ratio)  #Flatten values of ratio between counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b589a65-3c10-405d-b762-cbc4827c72c2",
   "metadata": {},
   "source": [
    "## 4.1 - Rescale valores de 2Dhist(cos(α), time_res) normalizado por NHits en el rango de la variable Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "585ddd38-27b0-4874-8520-18e41c26a74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_val = np.min(ratio)\n",
    "max_val = np.max(ratio)\n",
    "\n",
    "scaler = MinMaxScaler((min_val, max_val))\n",
    "scaler.fit(H_normalized1)\n",
    "sys_scale_H = scaler.transform(H_normalized1)\n",
    "\n",
    "#PLOT------------\n",
    "\n",
    "if radi_cut_method == True:\n",
    "    N1title = 'Rescaling by Ratio = (mc_pos/recons_pos) - Norm NHits - Multiple evID - 2.5MeV \\n random (dir, vtx) volume cut r(mm) < '+str(rad_cut_val)\n",
    "\n",
    "else:\n",
    "    N1title = 'Rescaling by Ratio - Norm NHits(mc_pos/recons_pos) - Multiple evID - 2.5MeV \\n random (dir, vtx)'\n",
    "    \n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(sys_scale_H, extent = [left, right, top, bottom], aspect=\"auto\" )\n",
    "plt.title(N1title, fontsize= 10)\n",
    "plt.ylabel(ylabel)\n",
    "plt.xlabel(xlabel)\n",
    "plt.colorbar()\n",
    "#plt.savefig('figs/Low Stat/Rescaling by Ratio Norm NHits 10MeV random (dir, vtx) '+str(rad_cut_val)+'_'+str(bins)+'.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76787aa4-4a6a-477a-9b29-584259960310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
